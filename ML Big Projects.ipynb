{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6e12eb",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\" >Machine Learning Big Projects Series: </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f0bb4",
   "metadata": {},
   "source": [
    "<img height=200 width=600 src=\"2.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6a1ec",
   "metadata": {},
   "source": [
    "The ML Big Project Series aims to create a comprehensive end-to-end application by showcasing a diverse range of machine learning skills and concepts through a series of engaging and practical projects. These projects provide a hands-on learning experience for experimenting with various machine learning techniques and their real-world applications. The focus is on practical implementation and learning through experimentation, making the process both enjoyable and informative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f4225",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "    \n",
    "- [Data Science Regression Project: Predicting Home Prices in Banglore](#0.0.)\n",
    "    - [1.0. Data Pre-processing:](#1.0.)\n",
    "        - [1.1. Data Cleaning:](#1.1.)\n",
    "        - [1.2. Feature Engineering: ](#1.2.)\n",
    "        - [1.3. Dimensionality Reduction: ](#1.3.)\n",
    "        - [1.4. Outlier Removal Using Business Logic: ](#1.4.)\n",
    "        - [1.5. Outlier Removal Using Standard Deviation and Mean:](#1.5.)\n",
    "        - [1.6. Outlier Removal Using Bathrooms Feature:](#1.6.)\n",
    "        - [1.7. Use One Hot Encoding For Location:](#1.7.)\n",
    "    - [2.0. Model Building:](#2.0.)\n",
    "        - [2.1. Use K Fold cross validation to measure accuracy of our LinearRegression model:](#2.1.)\n",
    "        - [2.2. Find best model using GridSearchCV:](#2.2.)\n",
    "        - [2.3. Test the model for few properties: ](#2.3.)\n",
    "    - [3.0. Export the tested model to a pickle file:](#3.0.)\n",
    "        - [3.1. Export location and column information to a file that will be useful later on in our prediction application:](#3.1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474dc5a4",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\" >Data Science Regression Project: Predicting Home Prices in Banglore</h1><a id='0.0.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0d34d",
   "metadata": {},
   "source": [
    "Project Brief: This project aims to develop a real estate price prediction website using a step-by-step process. The first step involves building a model using scikit-learn and linear regression, using the Bangalore home prices dataset from Kaggle.com. The second step is to develop a Python Flask server that will use the saved model to serve HTTP requests. The third component is a website built using HTML, CSS, and JavaScript that allows users to input a home's square footage, number of bedrooms, and other relevant features, and retrieve the predicted selling price by calling the Flask server.\n",
    "\n",
    "Throughout the project, we will cover a range of data science concepts, such as data cleaning, outlier detection and removal, feature engineering, dimensionality reduction, hyperparameter tuning using GridSearchCV, and k-fold cross-validation. We will also utilize various tools and technologies, including Python, NumPy, Pandas, Matplotlib, Jupyter Notebook, PyCharm, Python Flask, and HTML/CSS/JavaScript. The ultimate goal is to create an accurate predictive model that can estimate the value of a home based on its unique features, to assist buyers and sellers in making informed decisions.\n",
    "\n",
    "dataset credits: https://www.kaggle.com/amitabhajoy/bengaluru-house-price-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d088a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib \n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb08534",
   "metadata": {},
   "source": [
    "<h3>1.0. Data Pre-processing:</h3><a id='1.0.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd459bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a dataframe\n",
    "bhp = pd.read_csv(\"bengaluru_house_prices.csv\")\n",
    "bhp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c5a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18afb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c41cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp[\"area_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp[\"area_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82372348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary features to build the model\n",
    "bhp = bhp.drop(['area_type','availability','society','balcony'],axis = 'columns')\n",
    "bhp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a295f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a906ba5",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'> 1.1. Data Cleaning: </h3><a id='1.1.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18752f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "bhp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51748db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "bhp2 = bhp.dropna()\n",
    "bhp2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c462e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01724d1b",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>1.2. Feature Engineering: </h3><a id='1.2.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab133b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values in 'size' column\n",
    "bhp2['size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new feature 'bhk' \n",
    "bhp2['bhk'] = bhp2['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "bhp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp2.bhk.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5856a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows where 'bhk' value is greater than 20\n",
    "bhp2[bhp2.bhk>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdcca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore 'total_sqft' feature\n",
    "bhp2['total_sqft'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19efee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert string to float\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows where 'total_sqft' is not a float\n",
    "bhp2[~bhp2['total_sqft'].apply(is_float)].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1eab1",
   "metadata": {},
   "source": [
    "The above data indicates that the total square footage can be presented as a range, such as in the case of 2100-2850. To handle such scenarios, we can compute the average of the minimum and maximum values in the range. Additionally, there may be instances, such as with 34.46 square meters, where unit conversion is required to convert the area to square footage. However, for the sake of simplicity, we will remove such corner cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9602ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert range values to float\n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function with a single value\n",
    "convert_sqft_to_num('2100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c614c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function with a range value\n",
    "convert_sqft_to_num('2100 - 2850')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f09658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function with a corner case\n",
    "convert_sqft_to_num('34.46Sq. Meter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe\n",
    "bhp3 = bhp2.copy()\n",
    "# Convert 'total_sqft' values to float\n",
    "bhp3.total_sqft = bhp3.total_sqft.apply(convert_sqft_to_num)\n",
    "# Remove rows with null values in 'total_sqft' column\n",
    "bhp3 = bhp3[bhp3.total_sqft.notnull()]\n",
    "bhp3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a specific row\n",
    "bhp3.loc[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5519cb",
   "metadata": {},
   "source": [
    "The above information indicates that the total_sqft is 2475, which is obtained by taking the average of the range 2100-2850, that is, ((2100+2850)/2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new feature called 'price_per_sqft'\n",
    "bhp4 = bhp3.copy()\n",
    "# calculating price per sqft by dividing price by total square feet area\n",
    "bhp4['price_per_sqft'] = bhp4['price']*100000/bhp4['total_sqft']\n",
    "bhp4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92108721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the statistics of 'price_per_sqft'\n",
    "bhp4['price_per_sqft'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pre-processed data to a new CSV file\n",
    "bhp4.to_csv(\"bhp.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e152fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bhp4.location.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2c2b9",
   "metadata": {},
   "source": [
    "Upon examining the locations variable, we observe that it is a categorical variable. However, we encounter the problem of the curse of dimensionality, where the number of locations is too high. Therefore, we need to apply dimensionality reduction techniques to reduce the number of locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the 'location' column which is a categorical variable with high cardinality\n",
    "# remove leading/trailing white spaces from each location value\n",
    "bhp4.location = bhp4.location.apply(lambda x: x.strip())\n",
    "# get the frequency of each location\n",
    "location_stats = bhp4['location'].value_counts(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total number of data points\n",
    "location_stats.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e55f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of locations with more than 10 data points\n",
    "len(location_stats[location_stats>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b754cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total number of unique locations\n",
    "len(location_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e614127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of locations with less than or equal to 10 data points\n",
    "len(location_stats[location_stats<=10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f20f8",
   "metadata": {},
   "source": [
    "<h3 style=\"color:grey\">1.3. Dimensionality Reduction: </h3><a id='1.3.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec7ce2",
   "metadata": {},
   "source": [
    "To decrease the number of categories, we can label any location that has less than 10 data points as \"other.\" This will greatly reduce the number of categories. When we later perform one hot encoding, it will result in fewer dummy columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baacfd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform dimensionality reduction by tagging locations with less than 10 data points as 'other'\n",
    "location_stats_less_than_10 = location_stats[location_stats<=10]\n",
    "location_stats_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e866ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bhp4.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp4.location = bhp4.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\n",
    "len(bhp4.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9779648",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87385735",
   "metadata": {},
   "source": [
    "<h3 style=\"color:grey\">1.4. Outlier Removal Using Business Logic: </h3><a id='1.4.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a1c20",
   "metadata": {},
   "source": [
    "During a discussion with a business manager who has expertise in real estate, it was mentioned that a typical square footage per bedroom is 300. For instance, a 2 bhk apartment should be at least 600 sqft. If an apartment has 2 bhk and only 400 sqft of area, it can be considered as an outlier and removed. To remove such outliers, we will set the minimum threshold of square footage per bhk to be 300 sqft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a910a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using business logic - remove data points where total sqft per bhk is less than 300\n",
    "# Display the data points that satisfy the condition\n",
    "bhp4[bhp4.total_sqft/bhp4.bhk<300].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd08b5",
   "metadata": {},
   "source": [
    "Looking at the data points above, it is clear that there are errors in the dataset, such as a 6 bhk apartment with only 1020 sqft and an 8 bhk apartment with only 600 sqft. These data points can be safely removed as they do not align with typical real estate standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07950c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the data points that satisfy the condition and create a new dataset\n",
    "bhp5 = bhp4[~(bhp4.total_sqft/bhp4.bhk<300)]\n",
    "bhp5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4550f",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>1.5. Outlier Removal Using Standard Deviation and Mean: </h3><a id='1.5.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using standard deviation and mean\n",
    "bhp5.price_per_sqft.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ae762",
   "metadata": {},
   "source": [
    "The analysis reveals a large discrepancy in property prices, with the minimum price per sqft being 267 rs/sqft and the maximum being 12000000. To address this, we need to remove outliers based on the mean and one standard deviation per location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e672f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove the outliers per location using mean and one standard deviation\n",
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "\n",
    "# Remove the outliers using the above function and create a new dataset\n",
    "bhp6 = remove_pps_outliers(bhp5)\n",
    "bhp6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a2147",
   "metadata": {},
   "source": [
    "Let us analyze the prices of 2 BHK and 3 BHK properties for a given location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot the scatter chart for a given location, showing the prices of 2 BHK and 3 BHK properties\n",
    "def plot_scatter_chart(df,location):\n",
    "    # Filter data for 2 BHK and 3 BHK properties in the given location\n",
    "    bhk2 = df[(df.location==location) & (df.bhk==2)]\n",
    "    bhk3 = df[(df.location==location) & (df.bhk==3)]\n",
    "    # Set figure size and plot the scatter chart for both types of properties\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "\n",
    "# Plot scatter chart for 'Rajaji Nagar' and 'Hebbal' before removing outliers\n",
    "plot_scatter_chart(bhp6,\"Rajaji Nagar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_chart(bhp6,\"Hebbal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8ffdd",
   "metadata": {},
   "source": [
    "We need to ensure that the property prices are consistent for a given location. If the price of a 3 bedroom apartment is less than that of a 2 bedroom apartment with the same square footage in the same location, we should remove those properties as they are inconsistent. To achieve this, we will create a dictionary of statistics per number of bedrooms (BHK) for each location, such as shown below. Then, we can remove the 2 BHK apartments whose price_per_sqft is less than the mean price_per_sqft of the 1 BHK apartments in the same location.\n",
    "```\n",
    "{\n",
    "    '1' : {\n",
    "        'mean': 4000,\n",
    "        'std: 2000,\n",
    "        'count': 34\n",
    "    },\n",
    "    '2' : {\n",
    "        'mean': 4300,\n",
    "        'std: 2300,\n",
    "        'count': 22\n",
    "    },    \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outliers from the dataset based on price_per_sqft\n",
    "def remove_bhk_outliers(df):\n",
    "    # Create an empty array to store the indices of data points to be excluded from the dataset\n",
    "    exclude_indices = np.array([])\n",
    "    # Group the data by location and bhk and calculate the mean, standard deviation, and count of each group\n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df.price_per_sqft),\n",
    "                'std': np.std(bhk_df.price_per_sqft),\n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "        # Iterate through each bhk group for the current location and exclude data points whose price_per_sqft is less than the mean price_per_sqft of the previous bhk group (if it exists and has more than 5 data points)\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "    # Remove the excluded data points from the dataset and return the cleaned dataset\n",
    "    return df.drop(exclude_indices,axis='index')\n",
    "\n",
    "# Remove outliers from the dataset and store the cleaned dataset in a new variable\n",
    "bhp7 = remove_bhk_outliers(bhp6)\n",
    "# df8 = df7.copy()\n",
    "bhp7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a529609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter chart for 'Rajaji Nagar' and 'Hebbal' after removing outliers\n",
    "plot_scatter_chart(bhp7,\"Rajaji Nagar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_chart(bhp7,\"Hebbal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61253e5",
   "metadata": {},
   "source": [
    "Based on the charts above, it is clear that there are certain data points that are highlighted in red and they can be considered as outliers. These outliers are being removed by using the function called remove_bhk_outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of price_per_sqft to visualize the effect of removing outliers\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(bhp7.price_per_sqft,rwidth=0.8)\n",
    "plt.xlabel(\"Price Per Square Feet\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec044df3",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>1.6. Outlier Removal Using Bathrooms Feature: </h3><a id='1.6.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fea5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and remove outliers from the dataset based on the number of bathrooms\n",
    "bhp7.bath.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf380c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of number of bathrooms to visualize the distribution\n",
    "plt.hist(bhp7.bath,rwidth=0.8)\n",
    "plt.xlabel(\"Number of bathrooms\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb627d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the outliers where the number of bathrooms is greater than 10 and print those rows\n",
    "bhp7[bhp7.bath>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22432beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the business manager, having 2 more bathrooms than the number of bedrooms is unusual. \n",
    "# Therefore, we remove the outliers where the number of bathrooms is greater than the number of bedrooms + 2\n",
    "bhp7[bhp7.bath>bhp7.bhk+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee57447",
   "metadata": {},
   "source": [
    "During a conversation with the business manager,he pointed out that if a home has four bedrooms, the maximum number of bathrooms should be equal to the sum of total bedrooms and one guest bathroom. Any value higher than that indicates an outlier or a data error, and should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a23d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp8 = bhp7[bhp7.bath<bhp7.bhk+2]\n",
    "bhp8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'size' and 'price_per_sqft' columns as they are no longer required\n",
    "bhp9 = bhp8.drop(['size','price_per_sqft'],axis='columns')\n",
    "bhp9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a70a4a7",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>1.7. Use One Hot Encoding For Location: </h3><a id='1.7.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one hot encoding to convert the categorical 'location' column into numerical data for the model\n",
    "dummies = pd.get_dummies(bhp9.location)\n",
    "dummies.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the one-hot encoded 'location' columns with the original dataframe 'bhp9'\n",
    "# Drop the 'other' column from the one-hot encoded data as it is not required \n",
    "bhp10 = pd.concat([bhp9,dummies.drop('other',axis='columns')],axis='columns')\n",
    "bhp10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b05ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'location' column as we have now converted it to numerical data\n",
    "bhp11 = bhp10.drop('location',axis='columns')\n",
    "bhp11.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17339a3a",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>2.0. Model Building: </h3><a id='2.0.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48221a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ca61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets\n",
    "X = bhp11.drop(['price'],axis='columns')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ab4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bhp11.price\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Linear Regression to build the model and fit it on the training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "\n",
    "# Calculate the accuracy of the model on the testing data\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383b65b",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>2.1. Use K Fold cross validation to measure accuracy of our LinearRegression model: </h3><a id='2.1.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f108d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2cd87",
   "metadata": {},
   "source": [
    "After conducting 5 iterations, we observe that the model yields a score consistently above 80%. While this result is satisfactory, we aim to explore other regression algorithms to determine if we can achieve an even better performance. To accomplish this, we will utilize the GridSearchCV function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94200a9",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>2.2. Find best model using GridSearchCV: </h3><a id='2.2.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4836dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define the algorithms to test along with their respective hyperparameters\n",
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos = {\n",
    "        'linear_regression' : {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'copy_X': [True, False],\n",
    "                'n_jobs': [1, -1]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Initialize an empty list to store the results\n",
    "    scores = []\n",
    "    # Define the cross-validation method and number of splits\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    # Iterate through each algorithm and perform a grid search to find the best hyperparameters\n",
    "    for algo_name, config in algos.items():\n",
    "        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "    # Convert the results to a pandas dataframe and return it\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "# Call the function to find the best model\n",
    "find_best_model_using_gridsearchcv(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baae1b4",
   "metadata": {},
   "source": [
    "After analyzing the results, we can conclude that LinearRegression has the highest score among the algorithms tested. Therefore, we will use it as our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6b382",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'> 2.3. Test the model for few properties:  </h3><a id='2.3.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to predict the price given the location, sqft, bath and bhk\n",
    "def predict_price(location,sqft,bath,bhk):  \n",
    "    # Get the index of the location in the one-hot encoded columns\n",
    "    loc_index = np.where(X.columns==location)[0][0]\n",
    "    \n",
    "    # Create a feature vector of zeros with length equal to the number of columns\n",
    "    x = np.zeros(len(X.columns))\n",
    "    # Set the values for the sqft, bath and bhk features\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    # If the location is present in the dataset, set the corresponding feature value to 1\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "        \n",
    "    # Use the trained model to predict the price\n",
    "    return lr_clf.predict([x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295dc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model for a few properties\n",
    "predict_price('1st Phase JP Nagar',1000, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eacfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('1st Phase JP Nagar',1000, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Indira Nagar',1000, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58145baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Indira Nagar',1000, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4a05a",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>3.0. Export the tested model to a pickle file: </h3><a id='3.0.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb53627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the tested model to a pickle file\n",
    "import pickle\n",
    "with open('banglore_home_prices_model.pickle','wb') as f:\n",
    "    pickle.dump(lr_clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa51c2",
   "metadata": {},
   "source": [
    "<h3 style='color:grey'>3.1. Export location and column information to a file that will be useful later on in our prediction application: </h3><a id='3.1.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bccb41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
